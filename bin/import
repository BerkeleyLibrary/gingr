# frozen_string_literal: true

require 'thor'
require_relative '../lib/data_extractor'
require_relative '../lib/solr_indexer'
require_relative '../lib/geoserver_publisher'
require 'find'
require 'json'

module Gingr
  class Import < Thor
    desc 'solr index from a directory', 'Index json files from a directory to solr'
    option :solr_url
    option :change_reference_domain, type: :boolean, default: false
    def solr(dir_path)
      solr_url = options[:solr_url] || ENV['SOLR_URL']
      commit_within = options[:commit_within] || 5000
      indexer = SolrIndexer.new(solr_url)
      Find.find(dir_path) do |path|
        next unless File.extname(path).downcase == '.json'

        indexer.update(path, options[:change_reference_domain])
      rescue RSolr::Error::Http => e
        puts "Response body: #{e.response}"
      end
      indexer.solr.commit
    end

    desc 'publish a geofile', 'publish a geofile with basename to geoserver after this geofile moved to geoserver'
    option :geoserver_url
    def geoserver(filename)
      geoserver_url = options[:geoserver_url] || ENV['GEOSERVER_URL']
      publisher = GeoserverPublisher.new(geoserver_url)
      publisher.update(filename)
    end

    desc 'unpack zip file to a directory', 'unpack a zip file to a directory'
    option :spatial_root
    option :geoserver_root
    def unpack(zipfile)
      DataExtractor.spatial_root = spatial_root = options[:spatial_root] || ENV['SPATIAL_ROOT']
      DataExtractor.geoserver_root = options[:geoserver_root] || ENV['GEOSERVER_ROOT']

      extractor = DataExtractor.new()
      temp_path = File.join(Dir.pwd, File.basename(zipfile, ".*"))
      extractor.unzip(zipfile, temp_path)

      ingestion_files_path = File.join(temp_path, Config.ingestion_dirname)
      ingestion_files_path.children.select(&:directory?).each do |dir|
        extractor.move_files_from_dir(dir)
      end
    end

    def self.exit_on_failure?
      true
    end

  end
end

Gingr::Import.start(ARGV)
    # desc 'test solr', 'test solr'
    # def test_solr(ogm_path)
    #   solr_url = "http://solr:8983/solr/geodata-test"
    #   solr = RSolr.connect url: solr_url, adapter: :net_http_persistent
    #   Find.find(ogm_path) do |path|
    #     next unless File.extname(path).downcase == '.json'
     
    
    #       doc = JSON.parse(File.read(path))
    #       [doc].flatten.each do |record|
    #         # puts(record)
    #         # next unless record['dc_rights_s'].downcase == 'public'
    
    #         # puts "Indexing #{record['layer_slug_s']}: #{path}" # if $DEBUG
    #         # puts("Indexing #{record['dct_title_s']}: --- #{path}") # if $DEBUG
    #         solr.update params: { commitWithin: commit_within, overwrite: true },
    #                     data: [record].to_json,
    #                     headers: { 'Content-Type' => 'application/json' }
    #       end
    #   rescue RSolr::Error::Http => e
    #     puts e
    #   end
    #     solr.commit
    #   end

    # end

    # desc 'hello NAME', 'say hello to NAME'
    # option :from
    # def geoserver(name)
    #   puts "from: #{options[:from]}" if options[:from]
    #   puts "Hello #{name}"
    # end

    # desc 'hello NAME', 'say hello to NAME'
    # option :from
    # def sourc_file(name)
    #   puts "from: #{options[:from]}" if options[:from]
    #   puts "Hello #{name}"
    # end

    # desc 'hello NAME', 'say hello to NAME'
    # option :from
    # def all(name)
    #   puts "from: #{options[:from]}" if options[:from]
    #   puts "Hello #{name}"
    # end


