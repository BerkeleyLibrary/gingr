# frozen_string_literal: true

require 'thor'
require_relative '../lib/data_transfer_handler'
require_relative '../lib/solr_indexer'
require_relative '../lib/geoserver_publisher'
require 'find'
require 'json'

module Gingr
  # ingestion tasks
  class Import < Thor
    desc 'solr index within directory', 'Index json files from a directory to solr'
    option :solr_url
    option :change_reference_domain, type: :boolean, default: false
    def solr(dir_path)
      solr_url = options[:solr_url] || ENV['SOLR_URL']
      indexer = SolrIndexer.new(solr_url)
      Find.find(dir_path) do |path|
        next unless File.extname(path).downcase == '.json'

        indexer.update(path, options[:change_reference_domain])
      rescue RSolr::Error::Http => e
        puts "Response body: #{e.response}"
      end
      indexer.solr.commit
    end

    desc 'publish a geofile', 'tt'
    # long_desc <<-LONGDESC
    #      publish a geofile with inputs of file basename and access type to geoserver,#{' '}
    #      the geofile should have been already moved to geoserver before runng this task'
    # LONGDESC
    option :geoserver_url
    option :geoserver_root
    def geoserver(filename, access)
      geoserver_root = options[:geoserver_root] || ENV['GEOSERVER_ROOT']

      url = access == 'public' ? ENV['GEOSERVER_URL'] : ENV['GEOSERVER_SECURE_URL']
      geoserver_url = options[:geoserver_url] || url

      GeoserverPublisher.geoserver_root = geoserver_root
      GeoserverPublisher.access = access

      publisher = GeoserverPublisher.new(geoserver_url)
      publisher.update(filename)
    end

    desc 'unpack zip file to a directory', 'unpack a zip file to a directory'
    option :spatial_root
    option :geoserver_root
    def unpack(zipfile)
      DataTansferHandler.spatial_root = options[:spatial_root] || ENV['SPATIAL_ROOT']
      DataTansferHandler.geoserver_root = options[:geoserver_root] || ENV['GEOSERVER_ROOT']

      temp_path = File.join(Dir.pwd, 'temp', File.basename(zipfile, '.*'))
      # data_transfer_handler = DataTansferHandler.new
      # data_transfer_handler.extract_zipfile(zipfile, temp_path)
      puts temp_path
      subdirectory_paths(temp_path) do |dir|
        puts dir
        data_transfer_handler.move_ingestion_files(dir)
      end
      temp_path
    end

    # desc 'unpack zip file to a directory', 'unpack a zip file to a directory'
    # option :spatial_root
    # option :geoserver_root
    # def unpack(zipfile)
    #   DataTansferHandler.spatial_root = options[:spatial_root] || ENV['SPATIAL_ROOT']
    #   DataTansferHandler.geoserver_root = options[:geoserver_root] || ENV['GEOSERVER_ROOT']

    #   temp_path = File.join(Dir.pwd, 'temp', File.basename(zipfile, '.*'))
    #   data_transfer_handler = DataTansferHandler.new
    #   data_transfer_handler.unzip(zipfile, temp_path)

    #   ingestion_dirs(temp_path) do |dir|
    #     data_transfer_handler.move_ingestion_files(dir)
    #   end
    #   temp_path
    # end

    desc 'move, index and publish all files to related servers', 'tt'
    # long_desc <<-LONGDESC
    #       1) move all souce files and metadata files to apache server,#{' '}
    #       2) index all geoblacklight json files to solr,#{' '}
    #       3) publish all geofiles to geoserver
    # LONGDESC
    option :spatial_root
    option :geoserver_root
    option :solr_url
    option :change_reference_domain, type: :boolean, default: false
    option :geoserver_url
    option :spatial_root
    option :geoserver_root
    def all(zipfile)
      temp_path = unpack(zipfile)
      solr(temp_path)
      ingestion_dirs(temp_path) do |dir|
        Find.find(dir) do |file_path|
          next unless File.extname(file_path).downcase in ['.shp', 'tiff']

          filename = File.basename(file_path)
          geoserver(filename, access)
        end
      end
    end

    def ingestion_dirs(temp_path)
      # ingestion_files_path = File.join(temp_path, Config.ingestion_dirname)
      # x = Dir.each_child(ingestion_files_path)(&:directory?)
      # puts x
    end

    def subdirectory_paths(directory_path)
      Dir.children(directory_path)
         .map { |sub| File.join(directory_path, sub) }
         .select { |path| File.directory?(path) }
    end

    # def subdirectory_paths(directory_path)
    #   paths = []
    #   Dir.each_child(directory_path) do |sub|
    #     subdirectory_path = File.join(directory_path, sub)
    #     next unless File.directory? subdirectory_path
    #       paths << subdirectory_path
    #   end
    #   paths
    # end

    def access_type(dir)
      json_filepath = File.join(dir, 'geoblacklight.json')
      json_data = File.read(json_filepath)
      data_hash = JSON.parse(json_data)
      data_hash['dct_accessRights_s'].downcase == 'public' ? 'public' : 'UCB'
    end

    def self.exit_on_failure?
      true
    end
  end
end
Gingr::Import.start(ARGV)
